{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>This is a place where I host some documentation related to courses I give.</p>"},{"location":"Knime/","title":"Setting up a working Knime for AI practice","text":""},{"location":"Knime/#knime-installation","title":"Knime installation","text":"<ol> <li>Go to https://www.knime.com/downloads</li> <li>Register </li> <li>Download knime for your platform -- Be careful to download the appropriate version for your computer!</li> <li>Be patient, it's a large file to download...</li> <li>Install knime</li> </ol>"},{"location":"Knime/#knime-setup","title":"Knime setup","text":"<ol> <li>Open knime, and select a folder where your workflows will be placed</li> <li>Then, you should see something like  </li> <li>Click on \"i\" button at the top right (highlighted in previous picture)</li> <li>Scroll down to find \"Switch to classic user interface\" button and click on it </li> <li>Go to File &gt; Install KNIME Extensions</li> <li> <p>Install the following extensions:</p> <ul> <li>KNIME Optimization extension</li> <li>KNIME Textprocessing</li> <li>KNIME Deep learning - Keras integration</li> <li>KNIME Image processing</li> <li>KNIME Image processing - Deep Learning Extension </li> <li>KNIME Data generation</li> <li>KNIME Javascript Views (labs)</li> </ul> </li> <li> <p>It will take a while...</p> </li> <li>This is the list of extensions you should see if you click on \"already installed\" in the install extension menu.  </li> <li>Close KNIME</li> </ol>"},{"location":"Knime/#python-installation","title":"Python installation","text":"<p>The following steps are required only if anaconda is not installed on your computer.</p> <ol> <li> <p>Go to <code>anaconda</code> and download anaconda for your computer</p> </li> <li> <p>Install anaconda </p> </li> </ol>"},{"location":"Knime/#setup-knime-with-python","title":"Setup KNIME with Python","text":"<ol> <li>Open KNIME</li> <li>Go to File &gt; Preferences</li> <li>Navigate to KNIME &gt; Python (legacy)  </li> <li>Select Python 3 at the top</li> <li>Select <code>conda</code> as python environment configuration</li> <li>Don't worry about python2 (we will not use it)</li> <li>For Python 3, click on \"Create new environment\"</li> <li>This will take a while...</li> <li>When completed reset KNIME</li> </ol>"},{"location":"Knime/#python-environment-for-keras","title":"Python environment for Keras","text":"<p>For Keras, a specific environment is required.</p> <ol> <li>Open KNIME   </li> <li>Go to File &gt; Preferences</li> <li>Navigate to KNIME &gt; Python Deep Learning  </li> <li>Select \"Use special Deep learning configuration as defined below\"</li> <li>Select <code>Keras</code> as the library for DL Python</li> <li>Select <code>conda</code> as python environment configuration</li> <li>Don't worry about tensorflow 2 (we will not need it)</li> <li>For Keras, click on \"Create new environment\"</li> <li>For Windows/Intel MACs/Linux it should work. For Appel Silicon MAC, see below:</li> </ol>"},{"location":"Knime/#follow-the-steps-below-for-apple-silicon-m1m2-mac","title":"Follow the steps below for Apple silicon (M1/M2) Mac","text":"<p>Apple silicon (M1/M2) mac users</p> <p>For Apple Silicon macs, you will need to create manually an environment because the required libraries at old and they havn't been compiled for M1/M2</p> <ol> <li>Download Rosetta2 following this procedure</li> <li>On your Mac, go to Application &gt; Utilities and open the <code>Terminal</code> app</li> <li>On the terminal here are the commands you need to execute: <pre><code>$ CONDA_SUBDIR=osx-64 conda create -n py3_knime_keras python=3.6\n$ conda activate knime_keras\n$ conda install h5py=2.8 tensorflow-mkl=1.12 keras=2.2.4\n$ conda install pandas=0.23.0\n</code></pre></li> <li>Open KNIME </li> <li>Go to File &gt; Preferences</li> <li>Navigate to KNIME &gt; Python Deep Learning </li> <li>For Keras, choose  py3_knime_keras as environment.</li> </ol> Package list on my installation for Keras <pre><code>Package             Version\n------------------- ---------\nabsl-py             0.15.0\nastor               0.8.1\ncertifi             2021.5.30\ncoverage            5.5\nCython              0.29.24\ndataclasses         0.8\ngast                0.5.3\ngrpcio              1.36.1\nh5py                2.8.0\nimportlib-metadata  4.8.1\nKeras               2.2.4\nKeras-Applications  1.0.8\nKeras-Preprocessing 1.1.2\nMarkdown            3.3.4\nnumpy               1.19.2\npandas              0.23.0\npip                 21.2.2\nprotobuf            3.17.2\npython-dateutil     2.8.2\npytz                2021.3\nPyYAML              5.4.1\nscipy               1.5.2\nsetuptools          58.0.4\nsix                 1.16.0\ntensorboard         1.12.2\ntensorflow          1.12.0\ntermcolor           1.1.0\ntyping_extensions   4.1.1\nWerkzeug            2.0.3\nwheel               0.37.1\nzipp                3.6.0\n</code></pre>"},{"location":"Time%20Series/01_smoothing/","title":"Smoothing and forecasting","text":"<p>This document describes statistical methods that can used for time series smoothing and forecasting, with associated formulas and practical usage with Excel.</p>"},{"location":"Time%20Series/01_smoothing/#notations","title":"Notations","text":"<p>Here is a list of the notations used throughout this document</p> <ul> <li>\\(t\\): time, starts at 1, ends at \\(N\\), the number of sample</li> <li>\\(Y_t\\): the data value at time \\(t\\) </li> <li>\\(F_t\\): the forecasted value at time \\(t\\) </li> <li>\\(G_t\\): the smoothed value at time \\(t\\) </li> </ul>"},{"location":"Time%20Series/01_smoothing/#smoothing-versus-forecasting","title":"Smoothing versus forecasting","text":"<p>Smoothing is the action to remove local variations to get a smoothed version of the time series. It is used to estimate trend for instance, to get a large scale overview of how the values are going.</p> <p>Forecasting on the other end refers to predicting future values based on historical ones.</p> <p>Forecasting</p> <p>The current observation at time \\(t\\) can never be used in forecasting at time \\(t\\)</p> <p>To compare prediction or to optimize parameters, you can compute two metrics:</p> <ul> <li>MAE (Mean Absolute Error) which read:</li> </ul> <p>\\(\\displaystyle \\frac{1}{N} \\sum_t |Y_t - F_t|\\)</p> <ul> <li>MSE (Mean Square Error) which read:</li> </ul> <p>\\(\\displaystyle \\frac{1}{N} \\sum_t (Y_t - F_t)^2\\)</p>"},{"location":"Time%20Series/01_smoothing/#moving-average","title":"Moving average","text":"<p>Simple and efficient way to smooth the data, equivalent to the convolution of the signal by a window. Weighted moving average allows to control the weight of observation, shaping different types of window.</p>"},{"location":"Time%20Series/01_smoothing/#smoothing","title":"Smoothing","text":"<p>When using the moving average method to smooth the data (i.e. to soften sudden changes), then a central moving average is computed. Example to compute a CMA3:</p> <p>$\\displaystyle G_t = \\frac{Y_{t-1} + Y_{t} + Y_{t+1}}{3} $</p> <p>When the number of coefficient is even, then the formula reads (for CMA4):</p> <p>$\\displaystyle G_t = \\frac{\\frac{1}{2}Y_{t-2} + Y_{t-1} + Y_{t} + Y_{t+1} + \\frac{1}{2}Y_{t+2}}{3} $</p>"},{"location":"Time%20Series/01_smoothing/#forecast","title":"Forecast","text":"<p>Application</p> <p>Moving average is good for data with no trend and no seasonality!</p> <p>When using the moving average method to forecast (i.e. predict future values), then a moving average is computed on past values only! Example to compute a MA3:</p> <p>$\\displaystyle F_t = \\frac{Y_{t-3} + Y_{t-2} + Y_{t-1}}{3} $</p> <p>Weights can be applied:</p> <p>$\\displaystyle F_t = \\frac{w_3 Y_{t-3} + w_2 Y_{t-2} + w_1 Y_{t-1}}{w_1 + w_2 + w_3} $</p> <p>More generally for weighted MA of order \\(k\\):</p> <p>$\\displaystyle F_t = \\frac{1}{\\sum_{i=1}^{k} w_i} ~~\\sum_{i=1}^{k} w_{i} Y_{t-i}  $</p>"},{"location":"Time%20Series/01_smoothing/#simple-exponential-smoothing","title":"Simple exponential smoothing","text":"<p>Recursive way to smooth the data, with exponentially decreasing weights, controlled by one parameter: \\(\\alpha\\)</p>"},{"location":"Time%20Series/01_smoothing/#smoothing_1","title":"Smoothing","text":"<p>When smoothing data, the recursive formula reads:</p> <p>\\(G_1 = Y_1\\)</p> <p>\\(G_t = \\alpha Y_t + (1-\\alpha)G_{t-1}, \\,\\, t&gt;1\\)</p>"},{"location":"Time%20Series/01_smoothing/#forecast_1","title":"Forecast","text":"<p>Application</p> <p>Simple exponential smoothing is good for data with no trend and no seasonality!</p> <p>When forecasting data, the recursive formula reads:</p> <p>\\(F_1 = Y_1\\)</p> <p>\\(F_t = \\alpha Y_{t-1} + (1-\\alpha)F_{t-1}, \\,\\, t&gt;1\\)</p>"},{"location":"Time%20Series/01_smoothing/#double-exponential-smoothing","title":"Double exponential smoothing","text":"<p>The idea is to apply exponential smoothing twice (we use the result of the first smoothing to estimate the trend). In the course we use Brown's linear exponential smoothing. Double exponential smoothing is only used to do forecast.</p> <p>The recursive formula reads:</p> <p>\\(s'_1 = Y_1\\)</p> <p>\\(s'_t = \\alpha Y_t + (1-\\alpha)s'_{t-1}, \\,\\, t&gt;1\\)</p> <p>\\(s''_1 = s'_1 = Y_1, \\,\\, t&gt;1\\)</p> <p>\\(s''_t = \\alpha s'_t + (1-\\alpha)s''_{t-1}, \\,\\, t&gt;1\\)</p> <p>\\(a_t = 2s'_t - s''_t, \\,\\, t&gt;1\\)</p> <p>\\(b_t = \\frac{\\alpha}{\\alpha - 1} (s'_t - s''_t), \\,\\, t&gt;1\\)</p> <p>\\(\\displaystyle F_{t+m} = a_t + m b_t, \\,\\, t&gt;1\\)</p> <p>The \\(\\alpha\\) parameter</p> <p>The \\(\\alpha\\) parameter can be either fixed or optimized to reduce the error (MAE, MSE)</p> <p>Application</p> <p>Double exponential smoothing is good for data with trend but no seasonality!</p>"},{"location":"Time%20Series/01_smoothing/#alternative","title":"Alternative","text":"<p>Another way to apply exponential smoothing is Holt's linear, which uses 2 parameters (\\(\\alpha\\) and \\(\\beta\\)).</p> <p>\\(s_1 = Y_1\\)</p> <p>\\(b_1 = Y_2 - Y_1\\)</p> <p>\\(s_t =  \\alpha Y_t + (1-\\alpha)(s_{t-1} + b_{t-1}), \\, \\, t&gt;1\\)</p> <p>\\(b_t =  \\beta (s_t - s_{t-1}) + (1-\\beta)b_{t-1}, \\,\\, t&gt;1\\)</p> <p>\\(\\displaystyle F_{t+m} = s_t + m b_t, \\,\\, t&gt;1\\) </p>"},{"location":"Time%20Series/02_decomposition/","title":"Decomposition","text":"<p>This document describes statistical methods that can used for time series decomposition, with associated formulas and practical usage with Excel.</p> <p>To make better forecast, it is usually required to separate the time series into different parts:</p> <ul> <li>The trend \\(T_t\\): model the low frequency variation, can be fit to a linear evolution</li> <li>The seasonality component \\(S_t\\): model periodic variations. First step is to identify the period, and second step is to estimate \\(S_t\\)</li> <li>The residuals \\(R_t\\): the random variation, that should have zero mean</li> </ul> <p>There are two classical models (we will only focus on them for this course):</p> <ul> <li>the additive model, where \\(Y_t = T_t + S_t + R_t\\)</li> <li>the multiplicative model, where \\(Y_t = T_t \\times S_t \\times R_t\\)</li> </ul> <p>But more generally, each component can be either additive or multiplicative.</p>"},{"location":"Time%20Series/02_decomposition/#notations","title":"Notations","text":"<p>Here is a list of the notations used throughout this document</p> <ul> <li>\\(Y_t\\): the data value at time \\(t\\) </li> <li>\\(F_t\\): the forecasted value at time \\(t\\) </li> <li>\\(G_t\\): the smoothed value at time \\(t\\) </li> <li>\\(S_t\\): the seasonal coefficient at time \\(t\\)</li> <li>\\(R_t\\): the residual at time \\(t\\)</li> <li>\\(T_t\\): the trend at time \\(t\\)</li> </ul>"},{"location":"Time%20Series/02_decomposition/#step-by-step-methodology","title":"Step by step methodology","text":"<ol> <li>VIZ: Plot the time series, it is very important to take a look at the evolution of what you are studying. Clearly identify sampling frequency (daily, weekly, monthly, quarterly, yearly?).</li> <li>TREND: Identify if there is a trend, and whether trend is additive or multiplicative (is trend linear?)</li> <li>SEASONALITY: Identify if there is seasonality, and whether seasonality is additive or multiplicative (is the amplitude of period fluctuation increasing with time?) and it's period.</li> <li>MODEL: Build a model (additive or multiplicative for trend/seasonality) for your data and write the associated equation</li> </ol>"},{"location":"Time%20Series/02_decomposition/#model-selection","title":"Model selection","text":"Trend Seasonality Method No No Simple Exponential smoothing or Moving Average Yes No Double Exponential smoothing No Yes Decomposition (trend=0) Yes Yes Decomposition (trend linear)"},{"location":"Time%20Series/02_decomposition/#decomposition-methodology","title":"Decomposition methodology","text":"<ol> <li>ESTIMATE TREND: Estimate a trend \\(\\hat{TS_t}\\) using central moving average with a size equal to the seasonal periodicity. </li> <li>DETREND DATA: Compute the detrended time series:<ul> <li><code>Additive</code> \\(\\displaystyle D_t = Y_t - \\hat{TS_t}\\) </li> <li><code>Multiplicative</code> \\(\\displaystyle D_t = Y_t / \\hat{TS_t}\\) </li> </ul> </li> <li>ESTIMATE SEASONAL COMPONENT: Use \\(D_t\\) to estimate seasonal component. You should average the values of the coefficient for each period (for instance, average all January component for yearly seasonality and monthly data). This gives \\(\\hat{S_t}\\) which is periodic.</li> <li>REMOVE SEASONALITY TO FOCUS ON TREND: Estimate \\(A_t\\), the seasonally adjusted data, which should contain the trend and the residuals. We will use this data to perform a modelling of the trend:<ul> <li><code>Additive</code> \\(\\displaystyle A_t = Y_r - \\hat{S_t}\\)</li> <li><code>Multiplicative</code> \\(\\displaystyle A_t = Y_r / \\hat{S_t}\\)</li> </ul> </li> <li>MODEL TREND: At this point, a linear model is computed for \\(A_t\\) (in the course we only see linear models, but polynomial models could be used if trend is non-linear). This idea here is to model the trend as a straight line with a given slope and intercept (that can easily be computed with Excel functions <code>SLOPE</code> and <code>INTERCEPT</code>). Now \\(\\hat{A_t} = at + b\\). The linear fit is the same for additive and multiplicative models.</li> <li>COMPUTE RESIDUALS: Estimate the residuals:<ul> <li><code>Additive</code> \\(\\displaystyle R_t = Y_r - \\hat{A_t} - \\hat{S_t}\\)</li> <li><code>Multiplicative</code> \\(\\displaystyle R_t = \\frac{Y_r}{\\hat{T_t} \\times \\hat{S_t}}\\)</li> </ul> </li> <li>FORECAST RESIDUALS: Residuals should be trendless and should not exhibit seasonality, therefore they can be forecasted using traditionnal exponential smoothing. The forecasted residuals will be called \\(\\hat{R_t}\\)</li> <li>FORECAST: Now to compute the forecast, just apply <ul> <li><code>Additive</code> \\(\\displaystyle F_t = \\hat{A_t} + \\hat{S_t} + \\hat{R_t}\\)</li> <li><code>Multiplicative</code> \\(\\displaystyle F_t = \\hat{A_t} \\times \\hat{S_t} \\times \\hat{R_t}\\)</li> </ul> </li> </ol> <p>When using Excel to build such a model, you should have the following columns:</p> <ul> <li>\\(t\\): (1 to \\(N\\))</li> <li>\\(Y\\): Data points</li> <li>\\(\\hat{TS_t}\\): Central moving average with \\(k\\) points (k being the seasonal period)</li> <li>\\(D\\): Detrended time series for seasonal component estimation</li> <li>\\(S\\): Seasonal component</li> <li>\\(A\\): Seasonally adjusted component </li> <li>\\(T\\): \\(at + b\\) using \\(a\\) and \\(b\\) from the linear regression of \\(A\\) vs \\(t\\)</li> <li>\\(R\\): Residuals </li> <li>\\(\\hat{R}\\): Forecast of \\(R\\) using exponential smoothing with \\(\\alpha\\) being either fixed or solved to minimize the standard error.</li> <li>\\(RE\\): Residuals forecast error (\\(R_t-\\hat{R_t}\\))</li> <li>\\(F\\): Forecast of \\(Y\\)</li> <li>\\(SE\\): Standard error (\\(Y_t-F_t\\))</li> </ul>"},{"location":"Time%20Series/02_decomposition/#example","title":"Example","text":"<p>Here is an example of a time series decomposition.</p> <p></p>"},{"location":"Time%20Series/03_abc/","title":"ABC classification","text":"<p>ABC classification is a simple method to form 3 (or 4) groups of objects based on the distribution of some value associated with them. </p> <p>It is greatly inspired by the 80/20 Pareto rule, indicating that often 80% of a measure (for instance the revenue) comes from only 20% of objects (for instance customers).</p> <p>The archetypical example is to classify customers based on the amount of revenue they bring to a company.</p>"},{"location":"Time%20Series/03_abc/#definitions-and-notations","title":"Definitions and notations","text":"<ul> <li>We will consider \\(N\\) objects </li> <li>\\(M_i\\): the measure for object \\(i\\) that corresponds to the classification criterion</li> <li>\\(P_i\\): the proportion of \\(M_i\\) with respect to the total measure.</li> </ul> <p>\\(\\displaystyle P_i = \\frac{M_i}{\\sum_{i=1}^{N} M_i }\\) - \\(f\\): the frequency, which is equal to \\(1/N\\)</p>"},{"location":"Time%20Series/03_abc/#methodology","title":"Methodology","text":"<ol> <li>Define properly your business objective (what are the measure you are interested in? It may require to preprocess your data, building pivot tables for instance)</li> <li>Gather the data needed to perform the classification</li> <li>Identify the measure \\(M\\) that will be the classification criterion</li> <li>Sort your objects in descending order according to that measure</li> <li>Compute the frequency (constant \\(f\\)), the cumulated frequency (cumulative sum of \\(f\\)), the proportion \\(P_i\\) and the cumulative proportion (cumulative sum of \\(P_i\\))</li> <li>Plot a Pareto chart (cumulative proportion versus cumulative frequency)</li> <li>Plot also the diagonal line</li> <li>Classify your objects in 3 classes using the empirical rule defined below</li> </ol>"},{"location":"Time%20Series/03_abc/#excel-implementation","title":"Excel implementation","text":"<p>Using Excel, you should use the following columns to perform the classification:</p> <ul> <li>Object: The object your are considering</li> <li>\\(M\\): The measure that drives the classification for each object. Your table should be sorted in descending order based on that column</li> <li>\\(f\\): The frequency (\\(f = 1/N\\))</li> <li>\\(C_f\\): The cumulative frequency</li> <li>\\(P\\): The proportion of \\(M\\)</li> <li>\\(C_P\\): The cumulative proportion (cumulative sum of \\(P\\))</li> <li>\\(S_i\\): The trapeze area for the current point: \\(S_i = \\frac{1}{2} f (C_{P_i}+C_{P_{i-1}})\\). When \\(i=1\\), use \\(S_1 = \\frac{1}{2} f C_{P_i}\\)</li> </ul> <p>Then, outside your object table, you need to compute the following quantities:</p> <ul> <li>\\(S1\\): the area under the curve, which is the sum of \\(S\\): \\(\\displaystyle S1 = \\sum_{i=1}^{N} S_i\\)</li> <li>\\(S\\): the area between the diagonal and the curve: \\(S= S1-0.5\\)</li> <li>\\(B\\): the area above the curve: \\(B=1-S1\\)</li> <li>\\(G\\): the Gini index: \\(\\displaystyle G = \\frac{S}{S+B}\\)</li> </ul> <p>## Classification</p> <p>Then based on the value of the Gini index \\(G\\), you can use the following empirical rules:</p> G Class A Class B Class C \\(0.90 &lt; G &lt; 1.00\\) 10% 10% 80% \\(0.85 &lt; G &lt; 0.90\\) 10% 20% 70% \\(0.75 &lt; G &lt; 0.85\\) 20% 20% 60% \\(0.60 &lt; G &lt; 0.75\\) 20% 30% 50% <p>**\\(G &lt; 0.6\\) indicates that no classification can take place.</p> <p>This reads that if \\(G=0.95\\), the class A should contain the first 10% of objects, the class B the next 10% and class C all other customers.</p> <p>Similarly, if \\(G=0.70\\), the class A should contain the first 20% of objects, the class B the next 30% and class C all other customers.</p>"}]}